p8105_hw6_cl4776
================
Chenxi Liu
2025-12-01

# Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(broom)
library(purrr)

homicides <- readr::read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
homicides_clean <- homicides |>
mutate(
city_state = str_c(city, ", ", state),
resolved   = if_else(disposition == "Closed by arrest", 1, 0),
victim_age = as.numeric(victim_age),
victim_sex = factor(victim_sex, levels = c("Female", "Male")),
victim_race = factor(victim_race)
) |>
filter(
!city_state %in% c("Dallas, TX", "Phoenix, AZ",
"Kansas City, MO", "Tulsa, AL"),
victim_race %in% c("White", "Black")
)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `victim_age = as.numeric(victim_age)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

``` r
summary(homicides_clean$victim_age)
```

    ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
    ##    0.00   22.00   28.00   31.93   40.00  102.00     290

``` r
count(homicides_clean, city_state)
```

    ## # A tibble: 47 × 2
    ##    city_state          n
    ##    <chr>           <int>
    ##  1 Albuquerque, NM   178
    ##  2 Atlanta, GA       945
    ##  3 Baltimore, MD    2753
    ##  4 Baton Rouge, LA   410
    ##  5 Birmingham, AL    771
    ##  6 Boston, MA        492
    ##  7 Buffalo, NY       479
    ##  8 Charlotte, NC     584
    ##  9 Chicago, IL      4507
    ## 10 Cincinnati, OH    679
    ## # ℹ 37 more rows

``` r
baltimore <- homicides_clean |>
filter(city_state == "Baltimore, MD")

balt_glm <- glm(
resolved ~ victim_age + victim_sex + victim_race,
family = binomial,
data   = baltimore
)

balt_tidy <- balt_glm |>
tidy(conf.int = TRUE, exponentiate = TRUE)

balt_tidy
```

    ## # A tibble: 4 × 7
    ##   term             estimate std.error statistic  p.value conf.low conf.high
    ##   <chr>               <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
    ## 1 (Intercept)         1.36    0.171        1.81 7.04e- 2    0.976     1.91 
    ## 2 victim_age          0.993   0.00332     -2.02 4.30e- 2    0.987     1.000
    ## 3 victim_sexMale      0.426   0.138       -6.18 6.26e-10    0.324     0.558
    ## 4 victim_raceWhite    2.32    0.175        4.82 1.45e- 6    1.65      3.28

``` r
balt_OR_male <- balt_tidy |>
filter(term == "victim_sexMale") |>
select(term, estimate, conf.low, conf.high)

balt_OR_male
```

    ## # A tibble: 1 × 4
    ##   term           estimate conf.low conf.high
    ##   <chr>             <dbl>    <dbl>     <dbl>
    ## 1 victim_sexMale    0.426    0.324     0.558

``` r
city_models <- homicides_clean |>
group_by(city_state) |>
nest() |>
mutate(
model = map(
data,
~ glm(
resolved ~ victim_age + victim_sex + victim_race,
family = binomial,
data = .x
)
),
tidied = map(
model,
~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
)
) |>
unnest(tidied) |>
filter(term == "victim_sexMale") |>
select(city_state, estimate, conf.low, conf.high) |>
ungroup()

city_models
```

    ## # A tibble: 47 × 4
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    1.77     0.825     3.76 
    ##  2 Atlanta, GA        1.00     0.680     1.46 
    ##  3 Baltimore, MD      0.426    0.324     0.558
    ##  4 Baton Rouge, LA    0.381    0.204     0.684
    ##  5 Birmingham, AL     0.870    0.571     1.31 
    ##  6 Boston, MA         0.667    0.351     1.26 
    ##  7 Buffalo, NY        0.521    0.288     0.936
    ##  8 Charlotte, NC      0.884    0.551     1.39 
    ##  9 Chicago, IL        0.410    0.336     0.501
    ## 10 Cincinnati, OH     0.400    0.231     0.667
    ## # ℹ 37 more rows

``` r
city_OR_plot <- city_models |>
arrange(estimate) |>
mutate(city_state = factor(city_state, levels = city_state)) |>
ggplot(aes(x = city_state, y = estimate)) +
geom_hline(yintercept = 1, linetype = "dashed") +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1) +
coord_flip() +
labs(
title = "Adjusted Odds Ratios for Solving Homicides\nMale vs Female Victims",
x = "City",
y = "Odds Ratio (male vs female victims)"
) +
theme_minimal()

city_OR_plot
```

![](p8105_hw6_cl4776_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

The plot displays the adjusted odds ratio (OR) for solving homicides
comparing male to female victims across major U.S. cities, controlling
for victim age and race. Most cities have OR estimates close to 1 with
confidence intervals crossing 1, indicating little evidence of a
meaningful difference in clearance rates between male and female
victims. A few cities show ORs above or below 1, but wide confidence
intervals reflect substantial uncertainty or small sample sizes. An odds
ratio of 1 indicates no difference in clearance probability between male
and female victims, while values above or below 1 represent higher or
lower odds of being solved for male victims, respectively. Overall, the
results suggest that after adjustment, victim sex is not a strong
predictor of whether a homicide is solved in most cities.

# Problem 2

``` r
library(p8105.datasets)
data("weather_df")
```

``` r
weather_clean <- weather_df |>
drop_na(tmax, tmin, prcp)
set.seed(1)

bootstrap_results <- tibble(i = 1:5000) |>
mutate(
sample_df = map(i, ~ weather_clean |> slice_sample(prop = 1, replace = TRUE)),
models = map(sample_df, ~ lm(tmax ~ tmin + prcp, data = .x)),
glance_out = map(models, glance),
tidy_out   = map(models, tidy)
) |>
mutate(
r_squared = map_dbl(glance_out, ~ .x$r.squared),
beta_prod = map_dfr(tidy_out, ~
.x |>
filter(term %in% c("tmin", "prcp")) |>
summarise(prod = prod(estimate))
)$prod
)

bootstrap_results |>
ggplot(aes(x = r_squared)) +
geom_histogram(bins = 40, color = "white") +
theme_minimal() +
labs(
title = "Bootstrap Distribution of R²",
x = "R²",
y = "Count"
)
```

![](p8105_hw6_cl4776_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
bootstrap_results |>
ggplot(aes(x = beta_prod)) +
geom_histogram(bins = 40, color = "white") +
theme_minimal() +
labs(
title = "Bootstrap Distribution of β₁ × β₂",
x = "β₁ × β₂ (tmin × prcp)",
y = "Count"
)
```

![](p8105_hw6_cl4776_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

``` r
r2_CI <- quantile(bootstrap_results$r_squared, probs = c(0.025, 0.975))
beta_prod_CI <- quantile(bootstrap_results$beta_prod, probs = c(0.025, 0.975))

r2_CI
```

    ##      2.5%     97.5% 
    ## 0.9344957 0.9467211

``` r
beta_prod_CI
```

    ##         2.5%        97.5% 
    ## -0.008205826 -0.003773198

The bootstrap distribution for R² is approximately symmetric and
centered near the value obtained from the original data, indicating that
the fitted model explains a consistent proportion of the variation in
tmax across bootstrap samples. The distribution shows moderate
variability, and the 95% confidence interval reflects reasonable
uncertainty in the proportion of variance explained by tmin and prcp.

The distribution of β₁ × β₂ (the product of the coefficients for tmin
and prcp) is more skewed, with most values near zero but a noticeable
tail, likely because prcp has a small and variable effect. This skewness
suggests that the interaction-like quantity β₁β₂ is less stable across
bootstrap samples. The 95% confidence interval captures this skewed
uncertainty and includes values close to zero.
